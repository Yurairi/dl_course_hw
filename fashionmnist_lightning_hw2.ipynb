{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "B6c6WS_wnX_4",
      "metadata": {
        "id": "B6c6WS_wnX_4"
      },
      "source": [
        "# Домашнее задание 2 — FashionMNIST на PyTorch Lightning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "nHn7JMO8naAB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHn7JMO8naAB",
        "outputId": "5554a77f-9f1d-40c9-fe8f-7f2d94665938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
            "Downloading lightning-2.6.0-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.6.0 lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy torch torchvision lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qDOqr-Y_nX_5",
      "metadata": {
        "id": "qDOqr-Y_nX_5"
      },
      "source": [
        "Импорты, версии и воспроизводимость"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "rDABZ6QEnX_6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDABZ6QEnX_6",
        "outputId": "a53f3e07-e629-4af1-cbcd-bd0acd38502a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch: 2.9.0+cu126\n",
            "torchvision: 0.24.0+cu126\n",
            "lightning: 2.6.0\n",
            "torchmetrics: 1.8.2\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "print(\"lightning:\", pl.__version__)\n",
        "print(\"torchmetrics:\", torchmetrics.__version__)\n",
        "\n",
        "SEED = 42\n",
        "pl.seed_everything(SEED, workers=True)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_kznyPqvnX_6",
      "metadata": {
        "id": "_kznyPqvnX_6"
      },
      "source": [
        "## `FashionMNISTDataModule`\n",
        "\n",
        "Требования:\n",
        "- загрузка данных\n",
        "- предобработка: ToTensor + Normalize (+ опционально аугментации)\n",
        "- разбиение на train/val/test\n",
        "- dataloader'ы\n",
        "\n",
        "**Нормализация.** Для FashionMNIST обычно используют mean/std, оцененные по train. В литературе часто встречается `mean≈0.286`, `std≈0.353` для FashionMNIST. Здесь зададим эти значения явно.\n",
        "\n",
        "**Аугментации.**  Самый минимум: `RandomHorizontalFlip` (для одежды допустимо), можно добавить `RandomAffine` с малыми углами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "wkVKbODSnX_7",
      "metadata": {
        "id": "wkVKbODSnX_7"
      },
      "outputs": [],
      "source": [
        "class FashionMNISTDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir: str = \"./data\",\n",
        "        batch_size: int = 128,\n",
        "        num_workers: int = 4,\n",
        "        val_size: int = 5000,\n",
        "        seed: int = 42,\n",
        "        pin_memory: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.val_size = val_size\n",
        "        self.seed = seed\n",
        "        self.pin_memory = pin_memory\n",
        "        self.mean = (0.2860,)\n",
        "        self.std = (0.3530,)\n",
        "\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.Normalize(self.mean, self.std),\n",
        "        ])\n",
        "\n",
        "        self.test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std),\n",
        "        ])\n",
        "\n",
        "        self.ds_train = None\n",
        "        self.ds_val = None\n",
        "        self.ds_test = None\n",
        "\n",
        "    def prepare_data(self) -> None:\n",
        "        torchvision.datasets.FashionMNIST(self.data_dir, train=True, download=True)\n",
        "        torchvision.datasets.FashionMNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage in (None, \"fit\"):\n",
        "            full_train = torchvision.datasets.FashionMNIST(\n",
        "                self.data_dir, train=True, transform=self.train_transform, download=False\n",
        "            )\n",
        "\n",
        "            train_size = len(full_train) - self.val_size\n",
        "            if train_size <= 0:\n",
        "                raise ValueError(f\"val_size={self.val_size} слишком большой для train={len(full_train)}\")\n",
        "\n",
        "            g = torch.Generator().manual_seed(self.seed)\n",
        "            self.ds_train, self.ds_val = random_split(full_train, [train_size, self.val_size], generator=g)\n",
        "\n",
        "        if stage in (None, \"test\"):\n",
        "            self.ds_test = torchvision.datasets.FashionMNIST(\n",
        "                self.data_dir, train=False, transform=self.test_transform, download=False\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.ds_train,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory and torch.cuda.is_available(),\n",
        "            persistent_workers=self.num_workers > 0,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.ds_val,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory and torch.cuda.is_available(),\n",
        "            persistent_workers=self.num_workers > 0,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.ds_test,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory and torch.cuda.is_available(),\n",
        "            persistent_workers=self.num_workers > 0,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DbVlfQ0dnX_7",
      "metadata": {
        "id": "DbVlfQ0dnX_7"
      },
      "source": [
        "Проверяем, что все собирается и размеры корректные.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "sxGLIbjVnX_7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxGLIbjVnX_7",
        "outputId": "fa34fc45-74d5-404c-a354-5587771ee9c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 8.94MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.58MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.0MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch x: torch.Size([128, 1, 28, 28]) torch.float32\n",
            "batch y: torch.Size([128]) torch.int64 classes: 0 .. 9\n"
          ]
        }
      ],
      "source": [
        "dm = FashionMNISTDataModule(batch_size=128, num_workers=4, val_size=5000, seed=SEED)\n",
        "dm.prepare_data()\n",
        "dm.setup(\"fit\")\n",
        "\n",
        "x, y = next(iter(dm.train_dataloader()))\n",
        "print(\"batch x:\", x.shape, x.dtype)\n",
        "print(\"batch y:\", y.shape, y.dtype, \"classes:\", y.min().item(), \"..\", y.max().item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KQr7jLEKnX_7",
      "metadata": {
        "id": "KQr7jLEKnX_7"
      },
      "source": [
        "## `FashionMNIST` модель (`LightningModule`)\n",
        "\n",
        "Требования:\n",
        "- `training_step`, `validation_step`, `test_step`\n",
        "- метрики TorchMetrics: **F1**, **ROC AUC** на val/test\n",
        "- логирование loss/метрик по эпохам\n",
        "- подбор optimizer + lr-scheduler\n",
        "\n",
        "### Почему такая архитектура\n",
        "FashionMNIST - 28×28 (один канал), 10 классов, относительно простой датасет.\n",
        "- **CNN**: локальные признаки (края, формы) важны, и CNN учится на порядок эффективнее.\n",
        "- Архитектура: 3 блока Conv-BN-ReLU-Pool, потом FC.\n",
        "- Dropout чтобы чуть уменьшить переобучение.\n",
        "\n",
        "### Optimizer + Scheduler\n",
        "- **AdamW**: дефолт для CNN, weight decay адекватная регуляризация.\n",
        "- **ReduceLROnPlateau**: простая стратегия с EarlyStopping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "A2-Ws1mAnX_8",
      "metadata": {
        "id": "A2-Ws1mAnX_8"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import MulticlassF1Score, MulticlassAUROC\n",
        "\n",
        "class FashionMNIST(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 10,\n",
        "        lr: float = 1e-3,\n",
        "        weight_decay: float = 1e-4,\n",
        "        lr_factor: float = 0.5,\n",
        "        lr_patience: int = 2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.val_f1 = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n",
        "        self.val_auroc = MulticlassAUROC(num_classes=num_classes, average=\"macro\")\n",
        "\n",
        "        self.test_f1 = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n",
        "        self.test_auroc = MulticlassAUROC(num_classes=num_classes, average=\"macro\")\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _shared_step(self, batch: Tuple[torch.Tensor, torch.Tensor]):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        return loss, probs, preds, y\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, probs, preds, y = self._shared_step(batch)\n",
        "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, probs, preds, y = self._shared_step(batch)\n",
        "\n",
        "        self.val_f1.update(preds, y)\n",
        "        self.val_auroc.update(probs, y)\n",
        "\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"val_f1\", self.val_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"val_auroc\", self.val_auroc, on_step=False, on_epoch=True, prog_bar=False)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, probs, preds, y = self._shared_step(batch)\n",
        "\n",
        "        self.test_f1.update(preds, y)\n",
        "        self.test_auroc.update(probs, y)\n",
        "\n",
        "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"test_f1\", self.test_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"test_auroc\", self.test_auroc, on_step=False, on_epoch=True, prog_bar=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.lr,\n",
        "            weight_decay=self.hparams.weight_decay,\n",
        "        )\n",
        "        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            opt,\n",
        "            mode=\"min\",\n",
        "            factor=self.hparams.lr_factor,\n",
        "            patience=self.hparams.lr_patience,\n",
        "            min_lr=1e-6,\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": opt,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": sch,\n",
        "                \"monitor\": \"val_loss\",\n",
        "                \"interval\": \"epoch\",\n",
        "                \"frequency\": 1,\n",
        "            },\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o3sGioWNnX_8",
      "metadata": {
        "id": "o3sGioWNnX_8"
      },
      "source": [
        "Проверяем, что модель делает forward и выдает правильный shape.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "UPzDcW3xnX_8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPzDcW3xnX_8",
        "outputId": "0a1dda4d-ab86-4025-b7db-11a01ed59d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits: torch.Size([8, 10])\n"
          ]
        }
      ],
      "source": [
        "model = FashionMNIST()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(x[:8])\n",
        "print(\"logits:\", out.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RIlJlz1InX_8",
      "metadata": {
        "id": "RIlJlz1InX_8"
      },
      "source": [
        "## Обучение через `Trainer`\n",
        "\n",
        "Требования:\n",
        "- `EarlyStopping`\n",
        "- TensorBoard логирование\n",
        "- интерпретация по графикам\n",
        "- тест\n",
        "\n",
        "Добавим также `ModelCheckpoint`, чтобы сохранить лучший чекпоинт (по `val_f1`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0SL8ZdJwnX_8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476,
          "referenced_widgets": [
            "d2cd5e8db7ac4f029c13cb08de4bb98e",
            "c0cb18825ceb4fea8ec2a4ad73e8ee5b"
          ]
        },
        "id": "0SL8ZdJwnX_8",
        "outputId": "29fa5dce-a8ad-48dc-a10f-70bcf3b7443a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ features   │ Sequential        │ 92.9 K │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ classifier │ Sequential        │  1.3 K │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ criterion  │ CrossEntropyLoss  │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_f1     │ MulticlassF1Score │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ val_auroc  │ MulticlassAUROC   │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ test_f1    │ MulticlassF1Score │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ test_auroc │ MulticlassAUROC   │      0 │ train │     0 │\n",
              "└───┴────────────┴───────────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ features   │ Sequential        │ 92.9 K │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ classifier │ Sequential        │  1.3 K │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ criterion  │ CrossEntropyLoss  │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ val_f1     │ MulticlassF1Score │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ val_auroc  │ MulticlassAUROC   │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ test_f1    │ MulticlassF1Score │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ test_auroc │ MulticlassAUROC   │      0 │ train │     0 │\n",
              "└───┴────────────┴───────────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 94.2 K                                                                                           \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 94.2 K                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 94.2 K                                                                                           \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 94.2 K                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2cd5e8db7ac4f029c13cb08de4bb98e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "logger = TensorBoardLogger(save_dir=\"tb_logs\", name=\"fashionmnist_hw2\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
        "    ModelCheckpoint(monitor=\"val_f1\", mode=\"max\", save_top_k=1, filename=\"best-{epoch:02d}-{val_f1:.4f}\"),\n",
        "    LearningRateMonitor(logging_interval=\"epoch\"),\n",
        "]\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=30,\n",
        "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "    devices=1,\n",
        "    logger=logger,\n",
        "    callbacks=callbacks,\n",
        "    deterministic=True,\n",
        "    log_every_n_steps=50,\n",
        "    enable_checkpointing=True,\n",
        ")\n",
        "\n",
        "dm = FashionMNISTDataModule(batch_size=128, num_workers=4, val_size=5000, seed=SEED)\n",
        "model = FashionMNIST(lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "trainer.fit(model, datamodule=dm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CC7rlg0unX_9",
      "metadata": {
        "id": "CC7rlg0unX_9"
      },
      "source": [
        "## Тестирование лучшего чекпоинта\n",
        "\n",
        "Lightning автоматически хранит путь до лучшего чекпоинта в `trainer.checkpoint_callback.best_model_path`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "orEGgtmcnX_9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "54d04e9acb54420283e0fb088070a766",
            "fecdb21baf6c4aa5b63bb33996b2096d"
          ]
        },
        "id": "orEGgtmcnX_9",
        "outputId": "0075b978-41fa-449e-8062-b05c6a8d7aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best checkpoint: tb_logs/fashionmnist_hw2/version_0/checkpoints/best-epoch=25-val_f1=0.9204.ckpt\n",
            "Best val_f1: tensor(0.9204, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Restoring states from the checkpoint path at tb_logs/fashionmnist_hw2/version_0/checkpoints/best-epoch=25-val_f1=0.9204.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at tb_logs/fashionmnist_hw2/version_0/checkpoints/best-epoch=25-val_f1=0.9204.ckpt\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: Loaded model weights from the checkpoint at tb_logs/fashionmnist_hw2/version_0/checkpoints/best-epoch=25-val_f1=0.9204.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at tb_logs/fashionmnist_hw2/version_0/checkpoints/best-epoch=25-val_f1=0.9204.ckpt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54d04e9acb54420283e0fb088070a766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9942920804023743     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9108181595802307     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.25107261538505554    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m       test_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9942920804023743    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9108181595802307    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.25107261538505554   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 0.25107261538505554,\n",
              "  'test_f1': 0.9108181595802307,\n",
              "  'test_auroc': 0.9942920804023743}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_ckpt = trainer.checkpoint_callback.best_model_path\n",
        "best_score = trainer.checkpoint_callback.best_model_score\n",
        "print(\"Best checkpoint:\", best_ckpt)\n",
        "print(\"Best val_f1:\", best_score)\n",
        "\n",
        "test_results = trainer.test(model=None, datamodule=dm, ckpt_path=\"best\")\n",
        "test_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zXyPxlrcnX_9",
      "metadata": {
        "id": "zXyPxlrcnX_9"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54d04e9acb54420283e0fb088070a766": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fecdb21baf6c4aa5b63bb33996b2096d",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 79/79 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:03 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">25.12it/s</span>  \n</pre>\n",
                  "text/plain": "Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 79/79 \u001b[2m0:00:03 • 0:00:00\u001b[0m \u001b[2;4m25.12it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "c0cb18825ceb4fea8ec2a4ad73e8ee5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cd5e8db7ac4f029c13cb08de4bb98e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c0cb18825ceb4fea8ec2a4ad73e8ee5b",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 29/29 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 430/430 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:16 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">25.65it/s</span> <span style=\"font-style: italic\">v_num: 0.000 val_loss: 0.251      </span>\n                                                                                 <span style=\"font-style: italic\">val_f1: 0.909 train_loss: 0.193   </span>\n</pre>\n",
                  "text/plain": "Epoch 29/29 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 430/430 \u001b[2m0:00:16 • 0:00:00\u001b[0m \u001b[2;4m25.65it/s\u001b[0m \u001b[3mv_num: 0.000 val_loss: 0.251      \u001b[0m\n                                                                                 \u001b[3mval_f1: 0.909 train_loss: 0.193   \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "fecdb21baf6c4aa5b63bb33996b2096d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
